{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model on full training data...\n",
      "Epoch 1: Train Loss = 0.2213, Test Loss = 0.5750\n",
      "Epoch 10: Train Loss = 0.0019, Test Loss = 0.0065\n",
      "Epoch 20: Train Loss = 0.0013, Test Loss = 0.0045\n",
      "Epoch 30: Train Loss = 0.0013, Test Loss = 0.0042\n",
      "Epoch 40: Train Loss = 0.0012, Test Loss = 0.0041\n",
      "Epoch 50: Train Loss = 0.0011, Test Loss = 0.0041\n",
      "Epoch 60: Train Loss = 0.0010, Test Loss = 0.0040\n",
      "Epoch 70: Train Loss = 0.0010, Test Loss = 0.0039\n",
      "Epoch 80: Train Loss = 0.0010, Test Loss = 0.0039\n",
      "Epoch 90: Train Loss = 0.0009, Test Loss = 0.0038\n",
      "Epoch 100: Train Loss = 0.0010, Test Loss = 0.0038\n",
      "Epoch 110: Train Loss = 0.0009, Test Loss = 0.0038\n",
      "Epoch 120: Train Loss = 0.0009, Test Loss = 0.0037\n",
      "Epoch 130: Train Loss = 0.0009, Test Loss = 0.0036\n",
      "Epoch 140: Train Loss = 0.0009, Test Loss = 0.0036\n",
      "Epoch 150: Train Loss = 0.0009, Test Loss = 0.0037\n",
      "Epoch 160: Train Loss = 0.0008, Test Loss = 0.0035\n",
      "Epoch 170: Train Loss = 0.0008, Test Loss = 0.0035\n",
      "Epoch 180: Train Loss = 0.0008, Test Loss = 0.0035\n",
      "Epoch 190: Train Loss = 0.0008, Test Loss = 0.0034\n",
      "Epoch 200: Train Loss = 0.0008, Test Loss = 0.0032\n",
      "Training log saved to 'different_model/LSTM_training_log.csv'\n",
      "Test Loss: 0.0024\n",
      "\n",
      "Training GRU model on full training data...\n",
      "Epoch 1: Train Loss = 0.4745, Test Loss = 1.2226\n",
      "Epoch 10: Train Loss = 0.0073, Test Loss = 0.0264\n",
      "Epoch 20: Train Loss = 0.0018, Test Loss = 0.0073\n",
      "Epoch 30: Train Loss = 0.0014, Test Loss = 0.0055\n",
      "Epoch 40: Train Loss = 0.0013, Test Loss = 0.0050\n",
      "Epoch 50: Train Loss = 0.0012, Test Loss = 0.0047\n",
      "Epoch 60: Train Loss = 0.0011, Test Loss = 0.0046\n",
      "Epoch 70: Train Loss = 0.0011, Test Loss = 0.0045\n",
      "Epoch 80: Train Loss = 0.0010, Test Loss = 0.0044\n",
      "Epoch 90: Train Loss = 0.0010, Test Loss = 0.0043\n",
      "Epoch 100: Train Loss = 0.0010, Test Loss = 0.0042\n",
      "Epoch 110: Train Loss = 0.0010, Test Loss = 0.0040\n",
      "Epoch 120: Train Loss = 0.0010, Test Loss = 0.0039\n",
      "Epoch 130: Train Loss = 0.0009, Test Loss = 0.0038\n",
      "Epoch 140: Train Loss = 0.0009, Test Loss = 0.0038\n",
      "Epoch 150: Train Loss = 0.0009, Test Loss = 0.0037\n",
      "Epoch 160: Train Loss = 0.0008, Test Loss = 0.0035\n",
      "Epoch 170: Train Loss = 0.0008, Test Loss = 0.0035\n",
      "Epoch 180: Train Loss = 0.0008, Test Loss = 0.0033\n",
      "Epoch 190: Train Loss = 0.0007, Test Loss = 0.0032\n",
      "Epoch 200: Train Loss = 0.0007, Test Loss = 0.0031\n",
      "Training log saved to 'different_model/GRU_training_log.csv'\n",
      "Test Loss: 0.0023\n",
      "\n",
      "Training RNN model on full training data...\n",
      "Epoch 1: Train Loss = 0.2345, Test Loss = 0.6422\n",
      "Epoch 10: Train Loss = 0.0053, Test Loss = 0.0405\n",
      "Epoch 20: Train Loss = 0.0018, Test Loss = 0.0177\n",
      "Epoch 30: Train Loss = 0.0015, Test Loss = 0.0143\n",
      "Epoch 40: Train Loss = 0.0013, Test Loss = 0.0123\n",
      "Epoch 50: Train Loss = 0.0011, Test Loss = 0.0100\n",
      "Epoch 60: Train Loss = 0.0010, Test Loss = 0.0087\n",
      "Epoch 70: Train Loss = 0.0010, Test Loss = 0.0078\n",
      "Epoch 80: Train Loss = 0.0009, Test Loss = 0.0067\n",
      "Epoch 90: Train Loss = 0.0008, Test Loss = 0.0057\n",
      "Epoch 100: Train Loss = 0.0008, Test Loss = 0.0049\n",
      "Epoch 110: Train Loss = 0.0008, Test Loss = 0.0044\n",
      "Epoch 120: Train Loss = 0.0007, Test Loss = 0.0039\n",
      "Epoch 130: Train Loss = 0.0007, Test Loss = 0.0037\n",
      "Epoch 140: Train Loss = 0.0007, Test Loss = 0.0034\n",
      "Epoch 150: Train Loss = 0.0006, Test Loss = 0.0033\n",
      "Epoch 160: Train Loss = 0.0006, Test Loss = 0.0033\n",
      "Epoch 170: Train Loss = 0.0006, Test Loss = 0.0030\n",
      "Epoch 180: Train Loss = 0.0006, Test Loss = 0.0029\n",
      "Epoch 190: Train Loss = 0.0006, Test Loss = 0.0030\n",
      "Epoch 200: Train Loss = 0.0006, Test Loss = 0.0026\n",
      "Training log saved to 'different_model/RNN_training_log.csv'\n",
      "Test Loss: 0.0020\n",
      "Predictions saved to 'different_model/predictions.csv'\n",
      "Metrics saved to 'different_model/model_metrics.csv'\n",
      "All models trained and results saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 数据加载和预处理\n",
    "file_path = \"Dataset/Processed_NFLX.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "numeric_columns = data.columns[1:]\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data.iloc[:, 1:])\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns[1:])\n",
    "\n",
    "# 数据集划分\n",
    "train_size = int(len(data_scaled) * 0.7)\n",
    "val_size = int(len(data_scaled) * 0.15)\n",
    "\n",
    "train_data = data_scaled[:train_size]\n",
    "val_data = data_scaled[train_size:train_size + val_size]\n",
    "test_data = data_scaled[train_size + val_size:]\n",
    "\n",
    "# 创建时间序列数据\n",
    "def create_sequences(data, time_steps, target_column=\"Close\"):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        seq = data.iloc[i:i + time_steps].values\n",
    "        label = data.iloc[i + time_steps][target_column]\n",
    "        sequences.append((seq, label))\n",
    "    return sequences\n",
    "\n",
    "# 使用最佳 time_steps 创建数据集\n",
    "time_steps = 5\n",
    "full_train_data = pd.concat([train_data, val_data])\n",
    "full_train_sequences = create_sequences(full_train_data, time_steps, target_column=\"Close\")\n",
    "test_sequences = create_sequences(test_data, time_steps, target_column=\"Close\")\n",
    "\n",
    "full_train_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor([seq[0] for seq in full_train_sequences], dtype=torch.float32),\n",
    "    torch.tensor([seq[1] for seq in full_train_sequences], dtype=torch.float32).unsqueeze(-1)\n",
    "), batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor([seq[0] for seq in test_sequences], dtype=torch.float32),\n",
    "    torch.tensor([seq[1] for seq in test_sequences], dtype=torch.float32).unsqueeze(-1)\n",
    "), batch_size=32, shuffle=False)\n",
    "\n",
    "# 模型定义\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, model_type=\"LSTM\"):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = {\n",
    "            \"LSTM\": nn.LSTM(input_size, hidden_size, num_layers, batch_first=True),\n",
    "            \"GRU\": nn.GRU(input_size, hidden_size, num_layers, batch_first=True),\n",
    "            \"RNN\": nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        }[model_type]\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        return self.fc(rnn_out[:, -1, :])  # 取最后一个时间步的输出\n",
    "\n",
    "# 模型训练函数\n",
    "def train_final_model_with_logging(model, train_loader, test_loader, criterion, optimizer, epochs=200, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    results = {\"epoch\": [], \"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "\n",
    "        results[\"epoch\"].append(epoch + 1)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# 模型评估函数\n",
    "def evaluate_model(model, test_loader, criterion, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            predictions.append(y_pred.cpu().numpy().squeeze())\n",
    "            actuals.append(y_batch.cpu().numpy().squeeze())\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    test_loss = mean_squared_error(actuals, predictions)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    return test_loss, actuals, predictions\n",
    "\n",
    "# 保存预测值到单一文件格式\n",
    "def save_predictions_by_format(actuals, predictions_dict, output_folder, data, scaler):\n",
    "    # 创建与原始数据形状一致的零矩阵\n",
    "    dummy_data = np.zeros((len(actuals), scaler.min_.shape[0]))\n",
    "    # 仅填充目标列的实际值\n",
    "    target_index = data.columns.tolist().index(\"Close\") - 1  # 获取目标列在归一化数据中的索引\n",
    "    dummy_data[:, target_index] = actuals\n",
    "\n",
    "    # 反归一化实际值\n",
    "    actuals_actual_values = scaler.inverse_transform(dummy_data)[:, target_index]\n",
    "\n",
    "    # 初始化保存数据\n",
    "    data_dict = {\"Test Day\": np.arange(1, len(actuals) + 1), \"Actual\": actuals_actual_values}\n",
    "\n",
    "    # 反归一化预测值\n",
    "    for model_type, preds in predictions_dict.items():\n",
    "        dummy_data[:, target_index] = preds\n",
    "        preds_actual_values = scaler.inverse_transform(dummy_data)[:, target_index]\n",
    "        data_dict[f\"Predicted ({model_type})\"] = preds_actual_values\n",
    "\n",
    "    # 保存为 CSV 文件\n",
    "    predictions_df = pd.DataFrame(data_dict)\n",
    "    prediction_file = os.path.join(output_folder, \"predictions.csv\")\n",
    "    predictions_df.to_csv(prediction_file, index=False)\n",
    "    print(f\"Predictions saved to '{prediction_file}'\")\n",
    "\n",
    "# 评估指标计算\n",
    "def calculate_metrics(actual, predicted):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    rrmse = rmse / np.mean(actual)\n",
    "    mda = np.mean(np.sign(actual[1:] - actual[:-1]) == np.sign(predicted[1:] - predicted[:-1]))\n",
    "    return rmse, mae, r2, rrmse, mda\n",
    "\n",
    "# 创建保存结果的文件夹\n",
    "output_folder = \"different_model\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 超参数设置\n",
    "input_size = train_data.shape[1]\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "learning_rate = 0.0001\n",
    "epochs = 200\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "metrics_list = []\n",
    "predictions_dict = {}\n",
    "\n",
    "# 训练模型并保存结果\n",
    "for model_type in [\"LSTM\", \"GRU\", \"RNN\"]:\n",
    "    print(f\"\\nTraining {model_type} model on full training data...\")\n",
    "    model = RNNModel(input_size, hidden_size, num_layers, output_size, model_type)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    results = train_final_model_with_logging(model, full_train_loader, test_loader, criterion, optimizer, epochs, device)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    result_file = os.path.join(output_folder, f\"{model_type}_training_log.csv\")\n",
    "    results_df.to_csv(result_file, index=False)\n",
    "    print(f\"Training log saved to '{result_file}'\")\n",
    "\n",
    "    _, actuals, predictions = evaluate_model(model, test_loader, criterion, device)\n",
    "    predictions_dict[model_type] = predictions\n",
    "\n",
    "    rmse, mae, r2, rrmse, mda = calculate_metrics(actuals, predictions)\n",
    "    metrics_list.append({\"model\": model_type, \"RMSE\": rmse, \"MAE\": mae, \"R²\": r2, \"RRMSE\": rrmse, \"MDA\": mda})\n",
    "\n",
    "# 保存所有预测值到单一文件\n",
    "save_predictions_by_format(actuals, predictions_dict, output_folder, data, scaler)\n",
    "\n",
    "# 保存评估指标到 CSV\n",
    "\n",
    "      \n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_file = os.path.join(output_folder, \"model_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"Metrics saved to '{metrics_file}'\")\n",
    "\n",
    "print(\"All models trained and results saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
